# Google Antigravity 実践レポート - AIチャットアプリ開発体験

## 出典
- タイトル: Googleが発表したAIエディタ、Antigravityを触ってみた。~指示・実装・動作確認~
- URL: https://qiita.com/yokko_mystery/items/bb5615ebcd385a597c41
- 著者: @yokko_mystery (Yokko)
- 投稿日: 2025年11月19日
- 最終更新: 2025年11月21日
- 収集日: 2025年11月22日

## Google Antigravity とは何か

Googleが2025年11月18日（米国時間）に発表した、**エージェントファースト（agent-first）**の開発プラットフォームです。

開発者が直接コードを書く「従来のIDE」ではなく、AIエージェントを指揮・監督し、エージェントが自律的に「**計画 → 実装 → 検証**」までを遂行する新たなワークフローを実現しています。

## 主な特徴

### 1. エージェントファースト開発体験
開発者は「指示」を出すだけで、エージェントが計画を立て、コードを記述・実行・検証します。エディタ・ターミナル・ブラウザを横断してタスクを自律的に遂行する点が特徴です。

### 2. マネージャービューとエディタビュー

**マネージャービュー：**
- 複数ワークスペース・複数エージェントを一元管理
- 各エージェントの進行状況や成果物を俯瞰できる

**エディタビュー：**
- 従来のコード編集画面に近い操作感
- エージェントとの対話や修正も行える

### 3. 作業の可視化（Artifacts）
エージェントが生成する以下の成果物を自動で保存・表示：
- タスクリスト
- 実装プラン
- スクリーンショット／録画
- コード差分

開発者は作業の履歴や検証を容易に確認でき、信頼性の高い「検証可能な成果物」を得られます。

## 実践：AIチャットアプリの開発

### 1. インストール/起動
Antigravityは公式サイトからダウンロードできます。VSCodeのフォークなので見慣れた画面構成です。

**利用可能なモデル：**
- Gemini 3も利用可能

**Conversation Mode：**
- **Planning**: 複雑なタスクや調査、共同作業向け。実行前に計画を立てます
- **Fast**: シンプルなタスク向け。直接タスクを実行し、素早く完了させます

### 2. Agent Managerの起動
「Open Agent Manager」から「Agent Manager」を起動します。

Antigravityには複数エージェントや複数ワークスペースを束ねて管理できる「Agent Manager」が存在します。ここから新規プロジェクトを開始したり、別ワークスペースのタスク状況を一覧で確認できます。

### 3. 指示を入力（たった1文のプロンプト）

**入力した指示：**
「AIハムスターと会話できるチャットアプリを作成してください。」

**エージェントが実行した内容：**
1. プロジェクト初期化
2. Next.js + Tailwind CSSの構成生成
3. 画面レイアウト作成
4. Chat UIコンポーネント構築
5. API Routeによる簡易チャットロジックの生成
6. ローカル開発サーバーの起動

**画面の表示：**
- **左側**: リアルタイムに「実際にエージェントが実行している内容」を確認できる
- **右側のTaskパネル**: エージェントが自律的に作成した「タスク分解」がチェックリストとして表示される。どの工程を実行しているのかが一目で分かる

**注意点：**
AIチャットに必要なGEMINI_API_KEYの設定だけは手作業で行いました。

### 4. 実装完了後、Chromeでアプリが起動

この時に**Chrome拡張機能である Antigravity Browser Extension**をインストールしました。

視覚的フィードバックやユースケースについては公式サイトの「Why frontend developers choose Google Antigravity」もご参考ください。

実際にチャットができるか試してみると、ちゃんと応答が返ってきます。

### 5. 追加の指示を入力

**入力した指示：**
「AIキャラクターの名前をハム次郎にしてください。途中経過をスクショで記録してください」

**結果：**
- Chrome上でアプリが起動し、修正していく様子をリアルタイムで確認できた
- 「Playback available」と表示されていたので「View」をクリックすると、右側でAIが実施した実際の動作確認のキャプチャを見ることができた
- このキャプチャはArtifactとして保存されている

**重要な発見：**
Editor／Terminal／Browserをまたぐ作業が実現されていることがわかります。

追加の実装が完了すると、**Walkthrough**が作成され、指示した通りにキャプチャも一緒に保存してくれました。

### 6. ArtifactからUIの修正を依頼（2025/11/19 19:58 追記）

作成したArtifactは画面の右に一覧表示することが可能です。

**UI修正の手順：**

#### ①変更したい箇所をドラッグ選択
UI上で修正したい箇所がある場合、そのArtifactの画面キャプチャを選択し、変更したい箇所をドラッグします。

#### ②変更したい内容をコメント
- 絵文字の表示位置についてコメント
- 吹き出しの色も変えてほしいのでコメント

#### ③コメント内容通りに実装される！
コメントした内容が自動的に実装されます。

### 7. 単一画像の修正も可能（2025/11/19 23:50 追記）

ドラッグして対象箇所のUIを修正する方法ですが、**生成された単一の画像にも利用でき、綺麗に修正してくれる**ようです。

**例：**
カップケーキの箇所を選択、コメントを入力して修正依頼を実施

**技術的背景：**
Antigravityの画像生成や画面モック制作は**NanoBanana（Gemini 2.5 Flash Image）モデル**が担当しているとのことです。

参考: Welcome to Google Antigravity 🚀 (1:48-1:52)

## 活用方法のまとめ

### 1. 自然言語での開発指示
たった1文の指示で、完全なWebアプリケーションを構築できます。

### 2. リアルタイムの作業可視化
エージェントが何をしているのかをリアルタイムで確認でき、タスクの進行状況が明確です。

### 3. 自動的な動作確認とキャプチャ
ブラウザでの動作確認を自動で実施し、その様子をキャプチャとして記録します。

### 4. ビジュアルフィードバックによる修正
画面キャプチャ上で直接ドラッグ＆コメントすることで、UIの修正を指示できます。

### 5. クロスツール統合
Editor、Terminal、Browserをシームレスに統合し、エージェントが自律的に作業を進めます。

### 6. 検証可能な成果物（Artifacts）
すべての作業履歴、実装計画、動作確認の記録が自動的に保存されます。

## 技術スタック

- **フレームワーク**: Next.js + Tailwind CSS
- **AIモデル**: Gemini 3（コーディング）、NanoBanana/Gemini 2.5 Flash Image（画像生成）
- **拡張機能**: Antigravity Browser Extension
- **ベース**: VSCodeフォーク

## 対象ユーザー

- フロントエンド開発者
- フルスタック開発者
- プロトタイプを素早く作成したい開発者
- UI/UXの反復改善を効率化したい開発者
- AIエージェントを活用した開発ワークフローを試したい開発者
